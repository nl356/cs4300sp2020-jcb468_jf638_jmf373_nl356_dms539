# -*- coding: utf-8 -*-
"""P1IR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wCuqebhz6j74oib5_IOKnfR3yjQvKEdD
"""

from sklearn.feature_extraction.text import TfidfVectorizer
import numpy as np
import json
from movies.movies import *
from songs.songs import *

def build_vectorizer(max_features, stop_words, norm='l2'):
    return TfidfVectorizer(stop_words = stop_words, max_features = max_features, norm = norm)

def build_matrix():
  word_max = 5000
  movie_and_songs_by_words = np.empty([len(movieData)+len(songData), word_max])
  tfidf_vec = build_vectorizer(word_max, "english")

  words_list = []
  for i in movieData:
    words_list.append(i["description"])
  for i in songData:
    song_string = ""
    for j in i["lyrics"]:
      song_string= song_string + " " + j
    words_list.append(song_string)
  movie_and_songs_by_words = tfidf_vec.fit_transform(words_list).toarray()
  return movie_and_songs_by_words

def get_cos_sim(song, movie):    
    songID = song_name_to_index[song]
    movID = movie_name_to_index[movie]
    
    songTfIdf = movie_and_songs_by_words[songID]
    movTfIdf = movie_and_songs_by_words[movID]
    
    dot_product = np.dot(songTfIdf,movTfIdf)
    
    return dot_product

def main(song_input):
  # put somewhere else later so not called everytime
  movieData = read_movies_json()
  songData = read_songs_json()
  num_movies = len(movieData)

  movie_name_to_index = {}
  i=0
  for movieDict in movieData:
    movie_name_to_index[movieDict["name"]]=i
    i=i+1

  song_name_to_index = {}
  j = num_movies
  for songDict in songData:
    song_name_to_index[songDict["name"]]=j
    j=j+1

  movie_and_songs_by_words = build_matrix()
  #end bad stuff

  song_title = song_input["name"]
  sim_scores = []
  for movie in movieData:
    sim_scores.append((get_cos_sim(song_title, movie["name"]), movie["name"] ))
  
  return sorted(sim_scores, reverse = True)[0:5]